{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "397704cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 00:27:23.908177: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,LearningRateScheduler\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8963e",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/structured_data/time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203168c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM global variables\n",
    "# Sequences / window size\n",
    "WINDOW_SIZE=20\n",
    "# Number of days to forecast\n",
    "FCST_AMT=30\n",
    "# Epochs when training the model\n",
    "EPOCHS=100\n",
    "\n",
    "BATCH_SIZE=32\n",
    "SHUFFLE_BUFFER_SIZE=1000\n",
    "\n",
    "# Stock name\n",
    "STOCK='TSLA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61bb5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset states generated by Keras\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14d76df",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f8ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get 5 years of data\n",
    "# end = datetime.now()\n",
    "# start = datetime(end.year - 5, end.month, end.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d7bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloaded and saved to CSV the first time\n",
    "# df = yf.download(STOCK, start, end)\n",
    "# df.to_csv('TSLA_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "625d3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('TSLA_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c0e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date']=pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89361549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b60595",
   "metadata": {},
   "outputs": [],
   "source": [
    "series=df['Close'].values\n",
    "time=pd.to_datetime(df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44a01786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-10</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.398666</td>\n",
       "      <td>23.541332</td>\n",
       "      <td>24.343332</td>\n",
       "      <td>24.343332</td>\n",
       "      <td>99202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-11</th>\n",
       "      <td>24.660667</td>\n",
       "      <td>24.811333</td>\n",
       "      <td>24.015333</td>\n",
       "      <td>24.450666</td>\n",
       "      <td>24.450666</td>\n",
       "      <td>94632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-12</th>\n",
       "      <td>24.628000</td>\n",
       "      <td>24.794001</td>\n",
       "      <td>24.344000</td>\n",
       "      <td>24.440001</td>\n",
       "      <td>24.440001</td>\n",
       "      <td>75405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-13</th>\n",
       "      <td>24.676666</td>\n",
       "      <td>25.162666</td>\n",
       "      <td>24.450001</td>\n",
       "      <td>25.119333</td>\n",
       "      <td>25.119333</td>\n",
       "      <td>110488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-14</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.191334</td>\n",
       "      <td>24.288668</td>\n",
       "      <td>24.380667</td>\n",
       "      <td>24.380667</td>\n",
       "      <td>95064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-04</th>\n",
       "      <td>235.750000</td>\n",
       "      <td>239.369995</td>\n",
       "      <td>233.289993</td>\n",
       "      <td>235.580002</td>\n",
       "      <td>235.580002</td>\n",
       "      <td>104099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-05</th>\n",
       "      <td>233.869995</td>\n",
       "      <td>246.660004</td>\n",
       "      <td>233.699997</td>\n",
       "      <td>238.720001</td>\n",
       "      <td>238.720001</td>\n",
       "      <td>137971100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-06</th>\n",
       "      <td>242.919998</td>\n",
       "      <td>246.570007</td>\n",
       "      <td>239.169998</td>\n",
       "      <td>239.369995</td>\n",
       "      <td>239.369995</td>\n",
       "      <td>126436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>241.550003</td>\n",
       "      <td>244.080002</td>\n",
       "      <td>236.979996</td>\n",
       "      <td>242.639999</td>\n",
       "      <td>242.639999</td>\n",
       "      <td>107142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>240.270004</td>\n",
       "      <td>245.270004</td>\n",
       "      <td>239.270004</td>\n",
       "      <td>243.839996</td>\n",
       "      <td>243.839996</td>\n",
       "      <td>102980100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2018-12-10   24.000000   24.398666   23.541332   24.343332   24.343332   \n",
       "2018-12-11   24.660667   24.811333   24.015333   24.450666   24.450666   \n",
       "2018-12-12   24.628000   24.794001   24.344000   24.440001   24.440001   \n",
       "2018-12-13   24.676666   25.162666   24.450001   25.119333   25.119333   \n",
       "2018-12-14   25.000000   25.191334   24.288668   24.380667   24.380667   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-12-04  235.750000  239.369995  233.289993  235.580002  235.580002   \n",
       "2023-12-05  233.869995  246.660004  233.699997  238.720001  238.720001   \n",
       "2023-12-06  242.919998  246.570007  239.169998  239.369995  239.369995   \n",
       "2023-12-07  241.550003  244.080002  236.979996  242.639999  242.639999   \n",
       "2023-12-08  240.270004  245.270004  239.270004  243.839996  243.839996   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2018-12-10   99202500  \n",
       "2018-12-11   94632000  \n",
       "2018-12-12   75405000  \n",
       "2018-12-13  110488500  \n",
       "2018-12-14   95064000  \n",
       "...               ...  \n",
       "2023-12-04  104099800  \n",
       "2023-12-05  137971100  \n",
       "2023-12-06  126436200  \n",
       "2023-12-07  107142300  \n",
       "2023-12-08  102980100  \n",
       "\n",
       "[1259 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a35a8d",
   "metadata": {},
   "source": [
    "## Split into train, validation and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fab49da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation and test sets (70,20,10 % split)\n",
    "n = len(series)\n",
    "\n",
    "# Train set\n",
    "time_train = time[0:int(n*0.7)]\n",
    "x_train = series[0:int(n*0.7)]\n",
    "\n",
    "# Validation set\n",
    "time_valid = time[int(n*0.7):int(n*0.9)]\n",
    "x_valid = series[int(n*0.7):int(n*0.9)]\n",
    "\n",
    "# Test set\n",
    "time_test = time[int(n*0.9):]\n",
    "x_test = series[int(n*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e8da73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = int(n*0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99edc8e",
   "metadata": {},
   "source": [
    "## Baseline MA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd3a51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_forecast(series, window_size):\n",
    "    \"\"\"Generates a moving average forecast\n",
    "\n",
    "    Args:\n",
    "      series (array of float) - contains the values of the time series\n",
    "      window_size (int) - the number of time steps to compute the average for\n",
    "\n",
    "    Returns:\n",
    "      forecast (array of float) - the moving average forecast\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a list\n",
    "    forecast = []\n",
    "\n",
    "    # Compute the moving average based on the window size\n",
    "    for time in range(len(series) - window_size):\n",
    "        forecast.append(series[time:time + window_size].mean())\n",
    "\n",
    "    # Convert to a numpy array\n",
    "    forecast = np.array(forecast)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3486b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MA predictions for entire dataframe then take just the test set slice (last 126 items)\n",
    "ma_pred = moving_average_forecast(series, 30)[-(n - test_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0596b072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_predictions = pd.DataFrame(ma_pred, index=time_test, columns=['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f04b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA RMSE: 27.42\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(x_test, test_predictions))\n",
    "print(f'{STOCK} RMSE: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7d7ac",
   "metadata": {},
   "source": [
    "## Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f86d2477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train.reshape(-1,1))\n",
    "x_valid_scaled = scaler.transform(x_valid.reshape(-1,1))\n",
    "x_test_scaled = scaler.transform(x_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6156b20",
   "metadata": {},
   "source": [
    "## Prepare windowed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af8788fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    \"\"\"\n",
    "    Most of this method comes from the coursera tensorflow developer course.\n",
    "    \n",
    "    Generates dataset windows\n",
    "\n",
    "    Args:\n",
    "      series (array of float) - contains the values of the time series\n",
    "      window_size (int) - the number of time steps to include in the feature\n",
    "      batch_size (int) - the batch size\n",
    "      shuffle_buffer(int) - buffer size to use for the shuffle method\n",
    "\n",
    "    Returns:\n",
    "      dataset (TF Dataset) - TF Dataset containing time windows\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a TF Dataset from the series values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "    # Window the data but only take those with the specified size\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "\n",
    "    # Flatten the windows by putting its elements in a single batch\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "\n",
    "    # Create tuples with features and labels\n",
    "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
    "\n",
    "    # Shuffle the windows\n",
    "    if shuffle_buffer is not None:\n",
    "        dataset = dataset.shuffle(shuffle_buffer)\n",
    "\n",
    "    # Create batches of windows\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e887541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windows for training dataset\n",
    "dataset = windowed_dataset(x_train_scaled.flatten(), WINDOW_SIZE, BATCH_SIZE, SHUFFLE_BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8808020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windows for validation set to pass into model\n",
    "val_set = windowed_dataset(x_valid_scaled.flatten(), WINDOW_SIZE, BATCH_SIZE, SHUFFLE_BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e3bf93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.float64, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634756d8",
   "metadata": {},
   "source": [
    "## Build model for testing/tuning optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc2a0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the learning rate scheduler\n",
    "# lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "#     lambda epoch: 1e-8 * 10**(epoch / 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ac9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the model\n",
    "# model_tune = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "#                       input_shape=[None]),\n",
    "#     LSTM(50, return_sequences=True),\n",
    "#     Dropout(0.2),\n",
    "#     LSTM(50, return_sequences=False),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(1)\n",
    "# ])\n",
    "\n",
    "# # Set the optimizer\n",
    "# optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# # Set the training parameters\n",
    "# model_tune.compile(loss='mean_squared_error',\n",
    "#               optimizer=optimizer,\n",
    "#               metrics=[RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0091ccda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#history = model_tune.fit(dataset, epochs=100, validation_data=val_set, callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a342c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the learning rate array\n",
    "# lrs = 1e-8 * (10 ** (np.arange(100) / 20))\n",
    "\n",
    "# # Set the figure size\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Set the grid\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Plot the loss in log scale\n",
    "# plt.semilogx(lrs, history.history[\"loss\"])\n",
    "\n",
    "# # Increase the tickmarks size\n",
    "# plt.tick_params('both', length=10, width=1, which='both')\n",
    "\n",
    "# # Set the plot boundaries\n",
    "# plt.axis([1e-8, 1e-3, 0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1715b65",
   "metadata": {},
   "source": [
    "## Train model with optimal learning rate\n",
    "It appears that the optimal learning rate is about 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "909866fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping with validation set\n",
    "# Save best model with a model checkpoint\n",
    "cp = ModelCheckpoint(f'model1/', save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5e334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "     25/Unknown - 3s 11ms/step - loss: 0.1826 - root_mean_squared_error: 0.4273INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 9s 225ms/step - loss: 0.1735 - root_mean_squared_error: 0.4165 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1861\n",
      "Epoch 2/100\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0427 - root_mean_squared_error: 0.2066INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 177ms/step - loss: 0.0421 - root_mean_squared_error: 0.2052 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0323 - root_mean_squared_error: 0.1798 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1879\n",
      "Epoch 4/100\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 0.0313 - root_mean_squared_error: 0.1769INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 194ms/step - loss: 0.0314 - root_mean_squared_error: 0.1772 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1523\n",
      "Epoch 5/100\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 0.0288 - root_mean_squared_error: 0.1697INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 191ms/step - loss: 0.0278 - root_mean_squared_error: 0.1668 - val_loss: 0.0218 - val_root_mean_squared_error: 0.1476\n",
      "Epoch 6/100\n",
      "24/27 [=========================>....] - ETA: 0s - loss: 0.0266 - root_mean_squared_error: 0.1631INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 177ms/step - loss: 0.0262 - root_mean_squared_error: 0.1618 - val_loss: 0.0203 - val_root_mean_squared_error: 0.1425\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0240 - root_mean_squared_error: 0.1548 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0227 - root_mean_squared_error: 0.1507INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 176ms/step - loss: 0.0227 - root_mean_squared_error: 0.1507 - val_loss: 0.0187 - val_root_mean_squared_error: 0.1367\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0207 - root_mean_squared_error: 0.1439 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1400\n",
      "Epoch 10/100\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0195 - root_mean_squared_error: 0.1397INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 187ms/step - loss: 0.0195 - root_mean_squared_error: 0.1396 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0208 - root_mean_squared_error: 0.1442 - val_loss: 0.0189 - val_root_mean_squared_error: 0.1373\n",
      "Epoch 12/100\n",
      "24/27 [=========================>....] - ETA: 0s - loss: 0.0198 - root_mean_squared_error: 0.1408INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0191 - root_mean_squared_error: 0.1382 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1205\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0197 - root_mean_squared_error: 0.1402 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1263\n",
      "Epoch 14/100\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 0.0192 - root_mean_squared_error: 0.1385INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 145ms/step - loss: 0.0191 - root_mean_squared_error: 0.1383 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
      "Epoch 15/100\n",
      "24/27 [=========================>....] - ETA: 0s - loss: 0.0171 - root_mean_squared_error: 0.1307INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 158ms/step - loss: 0.0177 - root_mean_squared_error: 0.1331 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1102\n",
      "Epoch 16/100\n",
      "23/27 [========================>.....] - ETA: 0s - loss: 0.0181 - root_mean_squared_error: 0.1344INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 161ms/step - loss: 0.0177 - root_mean_squared_error: 0.1330 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1096\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0176 - root_mean_squared_error: 0.1326INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 157ms/step - loss: 0.0176 - root_mean_squared_error: 0.1326 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0176 - root_mean_squared_error: 0.1327 - val_loss: 0.0130 - val_root_mean_squared_error: 0.1142\n",
      "Epoch 19/100\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 0.0180 - root_mean_squared_error: 0.1341INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 146ms/step - loss: 0.0183 - root_mean_squared_error: 0.1352 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0183 - root_mean_squared_error: 0.1354 - val_loss: 0.0123 - val_root_mean_squared_error: 0.1110\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0170 - root_mean_squared_error: 0.1304INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 159ms/step - loss: 0.0170 - root_mean_squared_error: 0.1304 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1030\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0186 - root_mean_squared_error: 0.1365INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 142ms/step - loss: 0.0186 - root_mean_squared_error: 0.1365 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0988\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0166 - root_mean_squared_error: 0.1289 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1051\n",
      "Epoch 24/100\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 0.0158 - root_mean_squared_error: 0.1257INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 172ms/step - loss: 0.0167 - root_mean_squared_error: 0.1293 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0971\n",
      "Epoch 25/100\n",
      "24/27 [=========================>....] - ETA: 0s - loss: 0.0178 - root_mean_squared_error: 0.1335INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 165ms/step - loss: 0.0173 - root_mean_squared_error: 0.1317 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0962\n",
      "Epoch 26/100\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 0.0167 - root_mean_squared_error: 0.1291INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 182ms/step - loss: 0.0165 - root_mean_squared_error: 0.1283 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0934\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 0.0157 - root_mean_squared_error: 0.1255 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
      "Epoch 28/100\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 0.0167 - root_mean_squared_error: 0.1294INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 180ms/step - loss: 0.0164 - root_mean_squared_error: 0.1281 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0920\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 1s 17ms/step - loss: 0.0162 - root_mean_squared_error: 0.1274 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0987\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0165 - root_mean_squared_error: 0.1283 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0146 - root_mean_squared_error: 0.1210 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0151 - root_mean_squared_error: 0.1229 - val_loss: 0.0114 - val_root_mean_squared_error: 0.1069\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0141 - root_mean_squared_error: 0.1186 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0922\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0141 - root_mean_squared_error: 0.1188INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 189ms/step - loss: 0.0141 - root_mean_squared_error: 0.1188 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0907\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0152 - root_mean_squared_error: 0.1232 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0973\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0159 - root_mean_squared_error: 0.1261 - val_loss: 0.0084 - val_root_mean_squared_error: 0.0917\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0165 - root_mean_squared_error: 0.1284 - val_loss: 0.0104 - val_root_mean_squared_error: 0.1022\n",
      "Epoch 38/100\n",
      "24/27 [=========================>....] - ETA: 0s - loss: 0.0134 - root_mean_squared_error: 0.1158INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 169ms/step - loss: 0.0137 - root_mean_squared_error: 0.1171 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0904\n",
      "Epoch 39/100\n",
      "23/27 [========================>.....] - ETA: 0s - loss: 0.0141 - root_mean_squared_error: 0.1187INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 175ms/step - loss: 0.0147 - root_mean_squared_error: 0.1213 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0133 - root_mean_squared_error: 0.1154INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 176ms/step - loss: 0.0133 - root_mean_squared_error: 0.1154 - val_loss: 0.0080 - val_root_mean_squared_error: 0.0895\n",
      "Epoch 41/100\n",
      "23/27 [========================>.....] - ETA: 0s - loss: 0.0150 - root_mean_squared_error: 0.1226INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 5s 182ms/step - loss: 0.0147 - root_mean_squared_error: 0.1214 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0878\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0176 - root_mean_squared_error: 0.1325 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0193 - root_mean_squared_error: 0.1388 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 14ms/step - loss: 0.0151 - root_mean_squared_error: 0.1227 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0889\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0142 - root_mean_squared_error: 0.1193 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0879\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.0133 - root_mean_squared_error: 0.1153 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
      "Epoch 47/100\n",
      "21/27 [======================>.......] - ETA: 0s - loss: 0.0152 - root_mean_squared_error: 0.1231"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
    "                      input_shape=[None]),\n",
    "    LSTM(50, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Set the optimizer\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Set the training parameters\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=optimizer,\n",
    "              metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(dataset,epochs=100, validation_data=val_set, callbacks=[es,cp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac62ae",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7ec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forecast(model, series, window_size, batch_size):\n",
    "    \"\"\"Uses an input model to generate predictions on data windows\n",
    "\n",
    "    Args:\n",
    "      model (TF Keras Model) - model that accepts data windows\n",
    "      series (array of float) - contains the values of the time series\n",
    "      window_size (int) - the number of time steps to include in the window\n",
    "      batch_size (int) - the batch size\n",
    "\n",
    "    Returns:\n",
    "      forecast (numpy array) - array containing predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a TF Dataset from the series values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "    # Window the data but only take those with the specified size\n",
    "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "\n",
    "    # Flatten the windows by putting its elements in a single batch\n",
    "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
    "\n",
    "    # Create batches of windows\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "    # Get predictions on the entire dataset\n",
    "    forecast = model.predict(dataset)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
    "    \"\"\"\n",
    "    Visualizes time series data\n",
    "\n",
    "    Args:\n",
    "      time (array of int) - contains the time steps\n",
    "      series (array of int) - contains the measurements for each time step\n",
    "      format - line style when plotting the graph\n",
    "      start - first time step to plot\n",
    "      end - last time step to plot\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dimensions of the graph figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    labels=[\"True\",\"Predicted\"]\n",
    "    l=0\n",
    "    if type(series) is tuple:\n",
    "\n",
    "        for series_num in series:\n",
    "            # Plot the time series data\n",
    "            plt.plot(time[start:end], series_num[start:end], format,label=labels[l])\n",
    "            l+=1\n",
    "\n",
    "    else:\n",
    "      # Plot the time series data\n",
    "      plt.plot(time[start:end], series[start:end], format)\n",
    "\n",
    "    # Label the x-axis\n",
    "    plt.xlabel(\"Time\")\n",
    "\n",
    "    # Label the y-axis\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    # Overlay a grid on the graph\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add legend\n",
    "    plt.gca().legend()\n",
    "\n",
    "    # Draw the graph on screen\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312cd195",
   "metadata": {},
   "source": [
    "## Show train predictions / model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13110508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper function to generate predictions\n",
    "train_predictions = model_forecast(model, x_train_scaled[:-1], WINDOW_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737fbd8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inverse transform\n",
    "train_predictions = scaler.inverse_transform(train_predictions)\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_train[19:-1], (x_train[19:-1], train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba929ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(tf.keras.metrics.mean_squared_error(x_train[19:-1], train_predictions.flatten()).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fface2",
   "metadata": {},
   "source": [
    "## Load model and predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ca313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the original series \n",
    "# Plot test set\n",
    "# Align to predictions by shifting by window_size \n",
    "forecast_series = series[test_split - WINDOW_SIZE:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1759ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_series = scaler.transform(forecast_series.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f779155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model = load_model(f'model1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use helper function to generate predictions\n",
    "forecast = model_forecast(model, forecast_series, WINDOW_SIZE, BATCH_SIZE)\n",
    "\n",
    "# Inverse transform\n",
    "results = scaler.inverse_transform(forecast)\n",
    "\n",
    "# Plot the results\n",
    "plot_series(time_test, (x_test, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b922cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the RMSE\n",
    "print(np.sqrt(tf.keras.metrics.mean_squared_error(x_test.flatten(), results.flatten()).numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521092ab",
   "metadata": {},
   "source": [
    "## Forecast next 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sequence = scaler.transform(series[-20:].reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183489eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1366bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forecasts(model, last_sequence, forecast_length=FCST_AMT):\n",
    "    forecasts = []\n",
    "\n",
    "    for _ in range(forecast_length):\n",
    "        # Predict the next time step\n",
    "        forecast = model.predict(tf.reshape(last_sequence, (1, WINDOW_SIZE, 1)))\n",
    "\n",
    "        # Append the forecast to the results\n",
    "        forecasts.append(forecast[0, 0])\n",
    "\n",
    "        # Update the last sequence for the next prediction\n",
    "        # \"Roll\" the first data point to the bottom of the list\n",
    "        # This is so it can be deleted and replaced and the window will \n",
    "        # keep shifting down \n",
    "        last_sequence = np.roll(last_sequence, -1)\n",
    "        # Replace the last element with the latest forecast\n",
    "        last_sequence[-1] = forecast[0, 0]\n",
    "\n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23820a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecasts = generate_forecasts(model, last_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e29389",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_future = scaler.inverse_transform(np.array(forecasts).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc84b14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_future.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c7f815",
   "metadata": {},
   "source": [
    "## Visualize forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.filter(['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize results in dataframe\n",
    "df_past = data[['Close']].reset_index()\n",
    "df_past.rename(columns={'index': 'Date'}, inplace=True)\n",
    "df_past['Date'] = pd.to_datetime(df_past['Date'])\n",
    "df_past['Forecast'] = np.nan\n",
    "\n",
    "df_future = pd.DataFrame(columns=['Date', 'Close', 'Forecast'])\n",
    "df_future['Date'] = pd.date_range(start=df_past['Date'].iloc[-1] + pd.Timedelta(days=1), periods=FCST_AMT)\n",
    "df_future['Forecast'] = y_future.flatten()\n",
    "df_future['Close'] = np.nan\n",
    "\n",
    "results = df_past.append(df_future).set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1438235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title(f'{STOCK} LSTM Model Forecast')\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Close Price USD ($)', fontsize=18)\n",
    "plt.plot(results['Close'])\n",
    "plt.plot(results['Forecast'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
